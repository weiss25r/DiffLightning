data:
  dataset: MNIST #possible values: CIFAR10, CIFAR100, MNIST
  num_workers: 4
  val_split: 0.1 #fraction of training data used for validation
  batch_size: 128
  seed: 42
augmentation:
  horizontal_flip: 0
  vertical_flip: 0

training:
  lr: 0.0002
  T: 1000
  epochs: 100
  devices: 1
  patience: 30
  verbose: false

backbone:
  in_channels: 1 #change to 1 for MNIST
  base_channels: 128
  multipliers: 
    - 1
    - 2
    - 2
    - 2
  attention_resolutions:
    - 16
    - 4

logging:
  version: exp_1
  experiment_name: DDPM_MNIST_V1
  logging_dir: ./logs
  checkpoint_dir: checkpoints/
  checkpoint_name: ddpm-{epoch:02d}-{val_loss:.2f}
  log_every_n_steps: 10
  compute_fid_every_n_epochs: 5